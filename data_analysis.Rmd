---
title: "Untitled"
output: html_document
---
# Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# setting up environment
setwd("~/Yale/2022 Fall/Tobin RA")
# loading packages
library(readxl)
library(tidyverse)
library(lubridate)
library(Hmisc)
library(heplots)
library(ggExtra)

# loading data
load("allyears.RData")
dfList <- list(df_2015, df_2016, df_2017, df_2018, df_2019, df_2020)
```


# Checking Counts

## Checking Gender Counts
```{r}
### sanity check for gender counts ###
genderdist <- function(dat){
  hist1 <- ggplot(dat, aes(x=GENDER)) +
    geom_bar(stat="count", width=0.7, fill="steelblue")
  return(hist1)
}

genderdist(df_2015)
genderdist(df_2016)
genderdist(df_2017)
genderdist(df_2018)
genderdist(df_2019)
genderdist(df_2020)
```

There are a fairly even number of responses from both males and females across the years. It seems the proportion of "Other" resposnes has been slightly increasing. This could be due to better clarity for the option, shifts in social norms, or maybe better anti-discriminatory policy.

There are many NAs, we should discuss what to do with these later.

## Checking unique responses
```{r}
### response count stats
nrow(df_2015)
nrow(df_2016)
nrow(df_2017)
nrow(df_2018)
nrow(df_2019)
nrow(df_2020)
# number of responses changes a lot! Is this an issue?

### checking if there are duplicates within each year
length(unique(df_2015$PID))-nrow(df_2015)
length(unique(df_2016$PID))-nrow(df_2016)
length(unique(df_2017$PID))-nrow(df_2017)
length(unique(df_2018$PID))-nrow(df_2018)
length(unique(df_2019$PID))-nrow(df_2019)
length(unique(df_2020$PID))-nrow(df_2020)
# no duplicates within year
```

There are no duplicates within each year.

# Checking dates
```{r}
str(df_2015$UPDATE_DATE) 
# already in a date format!!

sum(is.na(df_2015$UPDATE_DATE))
# no NAs across all years (I deleted code for this)

# organizing dates by month
df_2015$newdates <- floor_date(df_2015$UPDATE_DATE, unit = "month")
df_2016$newdates <- floor_date(df_2016$UPDATE_DATE, unit = "month")
df_2017$newdates <- floor_date(df_2017$UPDATE_DATE, unit = "month")
df_2018$newdates <- floor_date(df_2018$UPDATE_DATE, unit = "month")
df_2019$newdates <- floor_date(df_2019$UPDATE_DATE, unit = "month")
df_2020$newdates <- floor_date(df_2020$UPDATE_DATE, unit = "month")


# seeing how dates are dispersed, checking for weird ones
date_hist <- function(x){
  hist1 <- ggplot(data = x, aes(x = newdates)) +
    geom_bar(stat = "count", fill="steelblue")
  return(hist1)
}

date_hist(df_2015)
date_hist(df_2016)
date_hist(df_2017)
date_hist(df_2018)
date_hist(df_2019)
date_hist(df_2020)
```

The first few years had some weird spreads of dates, I'll check these further individually.

```{r}
table(df_2015$newdates)
```
The dataframe for 2016 had survey response dates goinog all the way to december of 2017. I'm guessing we should remove these?

```{r}
table(df_2016$newdates)
```

The same is true for 2016.

```{r}
table(df_2017$newdates)
```

2017 had 2 extraneous dates from 2016. Weird.

All in all, things seem to be mostly in order. 


# Checking Industry

```{r}
dfList %>%
    lapply(., function(x) sum(is.na(x$Industry))) %>%
    unlist() /
  (dfList %>%
    lapply(., function(x) nrow(x)) %>%
    unlist())
```

There's about 10-15% data on industry missing from each year.

Let's see some breakdowns of these industries
```{r}
indhist <- function(x){
  hist1 <- ggplot(data=x, aes(x=Industry)) +
    geom_bar(stat="count", width=0.7, fill="steelblue")
  return(hist1)
}

lapply(dfList, indhist)

# for (i in 1:length(dfList)){
#   df_iter <- dfList[i]
#   table(df_iter$Industry)
# }
```

This is kind of messy, I'm not sure if we want to really get into the weeds with this yet.


# Checking yrs exp

```{r}
exphist <- function(x){
  hist1 <- ggplot(data=x, aes(x=YRS_EXP))+
    geom_bar(stat="count", width=0.7, fill="steelblue")
}
hist(df_2015$YRS_EXP)
lapply(dfList, exphist)
```

Some years have negative years of experience, we can remove those. Should we
remove rows or just insert NA? I'll stick with NA for now.

```{r}
df_2019 <- df_2019 %>% 
  mutate(YRS_EXP = replace(df_2019$YRS_EXP, df_2019$YRS_EXP < 0, NA))

df_2020 <- df_2020 %>% 
  mutate(YRS_EXP = replace(df_2020$YRS_EXP, df_2020$YRS_EXP < 0, NA))
```

Overall the spreads of work experience are right skewed, which makes sense.


# checking totalcomp spread
```{r}
salaryhist <- function(x){
  hist1 <- ggplot(data=x, aes(x=TCC)) +
    geom_density(fill = 'steelblue', alpha=0.75)
}
lapply(dfList, salaryhist)
```

There's a ton of outliers! We should make a cutoff for this. 

# Comparing F to M
```{r}
# trying to compare female to male
p1 <- ggplot(data = df_2015) +
        geom_boxplot(aes(x = GENDER, y = SALARY, col = GENDER),
                    width = 0.1) + # jittered
        theme(legend.position = c(0.1, .73), # adding legend
              plot.title = element_text(vjust = 0.25) # moving title
              ) +
        ylim(c(0, 250000)) +
  theme_bw()

# adding marginal histograms to scatterplot, not nec for box    
# p2 <- ggMarginal(p1, groupFill = TRUE, margins = "y") 

# overlaid histogram for salary vs gender
salaryhist <- function(x){
  x %>%
  filter(!is.na(GENDER)) %>%
  ggplot() +
    geom_density(aes(x = SALARY, fill = GENDER),
                 alpha=0.25) + 
    theme(legend.position = c(0.1, .73), # adding legend
          plot.title = element_text(vjust = 0.25)) + # moving title
    xlim(c(0,200000)) +
    theme_bw() +
    ylim(0, 3.5 * 10 ** (-5)) +
    scale_fill_manual(values = c("#FF0000", "#169B45", "#0F31D8"))
}

salaryhist(df_2015)
salaryhist(df_2016)
salaryhist(df_2017)
salaryhist(df_2018)
salaryhist(df_2019)
salaryhist(df_2020)

# note: need to normalize gender categories in data processing
```

```{r}
# chi-square quantile plot function, credit to JDRS
#A function to make chi-square quantile plots 
#to test for multivariate normality of data or residuals
CSQPlot<-function(vars,label="Chi-Square Quantile Plot"){
  #usually, vars is xxx$residuals or data from one group and label is for plot
  x<-cov(scale(vars),use="pairwise.complete.obs")
  squares<-sort(diag(as.matrix(scale(vars))%*%solve(x)%*%as.matrix(t(scale(vars)))))
  quantiles<-quantile(squares)
  hspr<-quantiles[4]-quantiles[2]
  cumprob<-c(1:length(vars[,1]))/length(vars[,1])-1/(2*length(vars[,1]))
  degf<-dim(x)[1]
  quants<-qchisq(cumprob,df=degf)
  gval<-(quants**(-1+degf/2))/(exp(quants/2)*gamma(degf/2)*(sqrt(2)**degf))
  scale<-hspr / (qchisq(.75,degf)-qchisq(.25,degf))
  se<-(scale/gval)*sqrt(cumprob*(1-cumprob)/length(squares))
  lower<-quants-2*se
  upper<-quants+2*se
  
  plot(quants,squares,col='red',pch=19,cex=1.2,xlab="Chi-Square Quantiles",
       ylab="Squared MH Distance",main=paste("Chi-Square Quantiles for",label),ylim=range(upper,lower, squares) , xlim=range(c(0,quants)))
  lines(c(0,100),c(0,100),col=1)
  lines(quants,upper,col="blue",lty=2,lwd=2)
  lines(quants,lower,col="blue",lty=2,lwd=2)
  legend("topleft",c("Data","95% Conf Limits"),lty=c(0,2),col=c("red","blue"),lwd=c(2,2),
         pch=c(19,NA))
}
#An example of usage of this function
#CSQPlot(danielaaov$residuals,label="Daniela MANOVA Residuals")
```

Note: tests for multivariate normality must have shorter tables, should I
just sample them?

```{r}

#CSQPlot(num2015) #error: not enough ram
#heplots::cqplot(num2015)
# library(QuantPsyc)
# mult.norm(num2015)$mult.test
# CSQPlot(sample_n(num2015,500))

cor(num2015$HOURLY_RATE, num2015$SALARY, use="complete.obs")
# interesting error - is it either salary or wage reported?
```